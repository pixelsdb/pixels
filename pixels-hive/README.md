# Pixels-Hive
SerDe is short for “Serializer and Deserializer.”

Hive uses SerDe (and !FileFormat) to read and write table rows.

HDFS files –> InputFileFormat –> <key, value> –> Deserializer –> Row object

Row object –> Serializer –> <key, value> –> OutputFileFormat –> HDFS files

## Note
Source code in this module partially refers to [ORC SerDe](https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcSerde.java).

Pixels Serde is tested on Hive 2.1 and 2.3. Other hive version which is compatible
with the SerDe API in Hive 2.3 should also work fine with Pixels SerDe.

## Usage
./bin/hive

1. In hive cli:
```sql
hive> add jar {PATH}/pixels-hive-0.1.0-SNAPSHOT-full.jar
```
You can also put `pixels-hive-0.1.0-SNAPSHOT-full.jar` in the path `apache-hive-2.1.1-bin/auxlib/`, and hive will load the jar when launching.

2. Create tables in hive with the syntax in 
[Hive Language Manual](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-Create/Drop/Alter/UseDatabase).
But use the following `ROW FORMAT` and `TABLEPROPERTY`:
```SQL
ROW FORMAT SERDE PPixelsSerDeelsInputFormat
OUTPUTFORMATPixelsInputFormat ("bind.pixels.tabPixelsOutputFormatrent necessary, and it should be synchronized with the orderPath
and compactPath in pixels metadata. `bind.pixels.table` specifies
which table in pixels to bind this hive table. Replace `schema_name`
and `table_name` with the right schema and table name in pixels.

**BUT** be careful: It is a good idea to create an EXTERNAL table, internal table will delete data
when the table is dropped. If there is data in the location, you will lost it.

3. Load data by pixels-load and then it is ready for your to execute queries in hive. 
Currently, we have only implemented `PixelsInputFormat` for hive,
so that data can not be loaded through Hive's `LOAD` command.
Before executing a query, set `hive.input.format` in the session:
```sh
set hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat;
```
The default `hive.input.format` is `CombineHiveInputFormat`, which
will not invoke our dynamic splitting algorithm to generate the input
splits for MapReduce jobs. So pixels SerDe currently rejects to read 
and process splits generated by `CombineHiveInputSplit`.

Besides, it would be a good idea to set a smaller bound for the max
reducers in a job, such as:
```sh
set hive.exec.reducers.max=16
```
Pixels is an efficient columnar store for wide tables.
And it is common for a very small part to be read from a split.
The default reducer number in Hive is estimated by the total size
of the input splits `(num_reducer=min(hive.exec.reducers.max, (total_input_size/N))`, which is generally much much larger than the
exact number of reducers we need. The default max reducers in Hive 
2.x is 1099.

## Where is the Logs

Pixels logs is included in the Hive log, of which the default location
is `\tmp\{user_name}\hive.log`